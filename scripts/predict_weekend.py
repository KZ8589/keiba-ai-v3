"""
æ”¹å–„ç‰ˆã‚ªãƒƒã‚ºçµ±åˆäºˆæ¸¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆ v2.4 - Keiba Intelligence
3ã‚«ãƒ†ã‚´ãƒªãƒ¼æ¨å¥¨ãƒ¬ãƒ¼ã‚¹ç‰ˆï¼ˆé‰„æ¿ãƒ»ä¸­ç©´ãƒ»å¤§ç©´ï¼‰
- äººæ°—ã®ç›²ç‚¹ï¼ˆã‚®ãƒ£ãƒƒãƒ—æŒ‡æ¨™ï¼‰ã«ã‚ˆã‚‹é¸å®š
- TOP4é¦¬åˆ¸ç¨®å¯¾å¿œï¼ˆå˜å‹ãƒ»é¦¬é€£ãƒ»3é€£è¤‡ãƒ»3é€£å˜ï¼‰
"""
import pandas as pd
import numpy as np
import sqlite3
import lightgbm as lgb
import json
from pathlib import Path
from datetime import datetime
import argparse
import warnings
import sys
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))
from learning.prediction_logger import PredictionLogger
warnings.filterwarnings('ignore')

# ============================================================
# è¨­å®š
# ============================================================
DB_PATH = Path('data/keiba.db')
CSV_DIR = Path('data/csv_imports')
ODDS_DIR = Path('data/csv_imports/odds')
ENTRY_DIR = Path('data/csv_imports/race card')
RESULTS_DIR = Path('data/csv_imports/results')
PREDICTION_DIR = Path('data/predictions')

# ã‚«ãƒ†ã‚´ãƒªãƒ¼å®šç¾©ï¼ˆé…å½“æœŸå¾…å€¤ãƒ™ãƒ¼ã‚¹ï¼‰
CATEGORY_CONFIG = {
    'TEPPAN': {
        'name': 'é‰„æ¿',
        'emoji': 'ğŸ”µ',
        'description': 'é«˜ç¢ºç‡ã§çš„ä¸­ã‚’ç‹™ã†',
        'bet_style': 'å …å®Ÿå‹',
        'target': 'å˜å‹100ã€œ350å††',
        # é¸å®šæ¡ä»¶: AIãƒ©ãƒ³ã‚¯1ä½ Ã— 1ã€œ2ç•ªäººæ°— Ã— ã‚ªãƒƒã‚º1.0ã€œ3.5å€
        'rank_max': 1,
        'popularity_max': 2,
        'odds_min': 1.0,
        'odds_max': 3.5,
    },
    'CHUUANA': {
        'name': 'ä¸­ç©´',
        'emoji': 'ğŸŸ¡',
        'description': 'é¦¬é€£2,000å††ä»¥ä¸Šã‚’ç‹™ã†',
        'bet_style': 'ãƒãƒ©ãƒ³ã‚¹å‹',
        'target': 'é¦¬é€£2,000ã€œ10,000å††',
        # é¸å®šæ¡ä»¶: AIãƒ©ãƒ³ã‚¯1ã€œ3ä½ Ã— 3ã€œ7ç•ªäººæ°— Ã— ã‚ªãƒƒã‚º5ã€œ20å€ Ã— ã‚®ãƒ£ãƒƒãƒ—+2ä»¥ä¸Š
        'rank_max': 3,
        'popularity_min': 3,
        'popularity_max': 7,
        'odds_min': 5.0,
        'odds_max': 20.0,
        'gap_min': 2,
    },
    'OOANA': {
        'name': 'å¤§ç©´',
        'emoji': 'ğŸ”´',
        'description': 'ä¸‡é¦¬åˆ¸ã‚’ç‹™ã†',
        'bet_style': 'é«˜é…å½“å‹',
        'target': 'é¦¬é€£10,000å††ä»¥ä¸Š',
        # é¸å®šæ¡ä»¶: AIãƒ©ãƒ³ã‚¯1ã€œ5ä½ Ã— 8ç•ªäººæ°—ä»¥ä¸‹ Ã— ã‚ªãƒƒã‚º20å€ä»¥ä¸Š Ã— ã‚®ãƒ£ãƒƒãƒ—+3ä»¥ä¸Š
        'rank_max': 5,
        'popularity_min': 8,
        'odds_min': 20.0,
        'gap_min': 3,
    }
}

# è²·ã„ç›®ç‚¹æ•°è¨­å®š
BET_CONFIG = {
    'TEPPAN': {
        'tansho': 1,      # â—ã®ã¿
        'umaren': 1,      # â—-â—‹
        'sanrenpuku': 6,  # â—-â—‹â–²-â—‹â–²â–³ 
        'sanrentan': 6,   # â—â†’â—‹â–²â†’â—‹â–²â–³
    },
    'CHUUANA': {
        'tansho': 1,
        'umaren': 2,      # â—-â—‹â–²
        'sanrenpuku': 12, # â—-â—‹â–²â–³-â—‹â–²â–³â˜†
        'sanrentan': 12,  # â—â†’â—‹â–²â†’â—‹â–²â–³â–³
    },
    'OOANA': {
        'tansho': 1,
        'umaren': 3,      # â—-â—‹â–²â–³
        'sanrenpuku': 19, # 2-4-7å½¢å¼
        'sanrentan': 24,  # â—â—‹â†’â—â—‹â–²â†’â—‹â–²â–³â–³â–³
    }
}

PLACE_CSV_TO_CODE = {
    'æœ­å¹Œ': '01', 'å‡½é¤¨': '02', 'ç¦å³¶': '03', 'æ–°æ½Ÿ': '04',
    'æ±äº¬': '05', 'ä¸­å±±': '06', 'ä¸­äº¬': '07', 'äº¬éƒ½': '08',
    'é˜ªç¥': '09', 'å°å€‰': '10'
}

PLACE_CODE_TO_NAME = {v: k for k, v in PLACE_CSV_TO_CODE.items() if len(k) == 2}
TRACK_TYPE_MAP = {'èŠ': 'èŠ', 'ãƒ€': 'ãƒ€ãƒ¼ãƒˆ', 'ãƒ€ãƒ¼ãƒˆ': 'ãƒ€ãƒ¼ãƒˆ'}


def detect_race_class(race_name):
    race_name = str(race_name)
    if 'G1' in race_name or 'ï¼§ï¼©' in race_name:
        return 'G1'
    elif 'G2' in race_name or 'ï¼§ï¼©ï¼©' in race_name:
        return 'G2'
    elif 'G3' in race_name or 'ï¼§ï¼©ï¼©' in race_name:
        return 'G3'
    elif 'æ–°é¦¬' in race_name:
        return 'æ–°é¦¬'
    elif 'æœªå‹åˆ©' in race_name:
        return 'æœªå‹åˆ©'
    elif '1å‹' in race_name or 'ï¼‘å‹' in race_name:
        return '1å‹'
    elif '2å‹' in race_name or 'ï¼’å‹' in race_name:
        return '2å‹'
    elif '3å‹' in race_name or 'ï¼“å‹' in race_name:
        return '3å‹'
    elif 'ã‚ªãƒ¼ãƒ—ãƒ³' in race_name or 'OP' in race_name:
        return 'OP'
    return 'æ¡ä»¶'


def is_graded_race(race_class):
    return race_class in ['G1', 'G2', 'G3']


def is_maiden_race(race_class):
    return race_class in ['æ–°é¦¬', 'æœªå‹åˆ©']


def parse_odds_key(key):
    key = str(key).strip()
    place_first = key[0]
    place_map = {'1': '01', '2': '02', '3': '03', '4': '04', '5': '05',
                 '6': '06', '7': '07', '8': '08', '9': '09', '0': '10'}
    place_code = place_map.get(place_first, '05')

    if len(key) == 10:
        race_no = int(key[5:7])
        horse_no = int(key[7:10])
    elif len(key) == 9:
        race_no = int(key[5:7])
        horse_no = int(key[7:9])
    else:
        race_no, horse_no = 0, 0
    return place_code, race_no, horse_no


def load_odds_csv(date_str):
    short_date = date_str[2:]
    odds_path = ODDS_DIR / f"OD{short_date}.CSV"
    if not odds_path.exists():
        print(f"âš ï¸  ã‚ªãƒƒã‚ºãƒ•ã‚¡ã‚¤ãƒ«ãªã—: {odds_path}")
        return None

    print(f"ğŸ“Š ã‚ªãƒƒã‚ºCSVèª­ã¿è¾¼ã¿: {odds_path}")
    df = pd.read_csv(odds_path, header=None, encoding='cp932')

    odds_df = pd.DataFrame({
        'race_key': df[0].astype(str).str.strip(),
        'odds_win': pd.to_numeric(df[7], errors='coerce'),
        'odds_place_low': pd.to_numeric(df[8], errors='coerce'),
        'odds_place_high': pd.to_numeric(df[9], errors='coerce')
    })

    parsed = odds_df['race_key'].apply(
        lambda x: pd.Series(parse_odds_key(x), index=['place_code', 'race_no', 'horse_no'])
    )
    odds_df = pd.concat([odds_df, parsed], axis=1)
    print(f"  â†’ {len(odds_df)}ä»¶")
    return odds_df


def load_entry_csv(date_str):
    short_date = date_str[2:]
    entry_path = ENTRY_DIR / f"DE{short_date}.CSV"
    if not entry_path.exists():
        print(f"âŒ å‡ºé¦¬è¡¨ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
        return None

    print(f"ğŸ“„ å‡ºé¦¬è¡¨CSVèª­ã¿è¾¼ã¿: {entry_path}")
    df = pd.read_csv(entry_path, encoding='cp932')
    print(f"  â†’ {len(df)}é ­")
    return df


def merge_entry_and_odds(entry_df, odds_df):
    entry_df['place_code'] = entry_df['å ´æ‰€'].map(PLACE_CSV_TO_CODE)
    entry_df['race_no'] = entry_df['R'].astype(int)
    entry_df['horse_no'] = entry_df['é¦¬ç•ª'].astype(int)

    entry_df['merge_key'] = (
        entry_df['place_code'] + '_' +
        entry_df['race_no'].astype(str).str.zfill(2) + '_' +
        entry_df['horse_no'].astype(str).str.zfill(2)
    )

    odds_df['merge_key'] = (
        odds_df['place_code'] + '_' +
        odds_df['race_no'].astype(str).str.zfill(2) + '_' +
        odds_df['horse_no'].astype(str).str.zfill(2)
    )

    merged = entry_df.merge(
        odds_df[['merge_key', 'odds_win', 'odds_place_low', 'odds_place_high']],
        on='merge_key', how='left'
    )

    odds_count = merged['odds_win'].notna().sum()
    print(f"  â†’ ã‚ªãƒƒã‚ºçµ±åˆ: {odds_count}/{len(merged)}ä»¶")
    return merged


def convert_to_predict_format(merged_df, date_str):
    date_formatted = f"20{date_str[0:2]}-{date_str[2:4]}-{date_str[4:6]}"

    records = []
    for _, row in merged_df.iterrows():
        place_code = row['place_code']
        race_no = int(row['race_no'])
        race_name = str(row['ãƒ¬ãƒ¼ã‚¹å'])
        race_class = detect_race_class(race_name)
        race_id = f"{date_formatted}_{place_code}_{race_no:02d}"

        record = {
            'race_id': race_id, 'date': date_formatted,
            'place_code': place_code,
            'place_name': PLACE_CODE_TO_NAME.get(place_code, 'ä¸æ˜'),
            'race_no': race_no, 'race_name': race_name,
            'race_class': race_class,
            'is_graded': is_graded_race(race_class),
            'is_maiden': is_maiden_race(race_class),
            'track_type': TRACK_TYPE_MAP.get(row['èŠãƒ»ãƒ€'], row['èŠãƒ»ãƒ€']),
            'distance': int(row['è·é›¢']),
            'horse_no': int(row['é¦¬ç•ª']),
            'horse_name': str(row['é¦¬å']).strip(),
            'horse_sex': row['æ€§åˆ¥'],
            'horse_age': int(row['å¹´é½¢']),
            'jockey_name': str(row['é¨æ‰‹']).strip(),
            'load_weight': float(row['æ–¤é‡']),
            'trainer_name': str(row['èª¿æ•™å¸«']).strip(),
            'odds_win': float(row['odds_win']) if pd.notna(row['odds_win']) else None,
            'odds_place_low': float(row['odds_place_low']) if pd.notna(row.get('odds_place_low')) else None,
            'gate_no': int(row['æ ']) if pd.notna(row.get('æ ')) and row.get('æ ') != 0 else None
        }
        records.append(record)

    pred_df = pd.DataFrame(records)
    field_sizes = pred_df.groupby('race_id').size().reset_index(name='field_size')
    pred_df = pred_df.merge(field_sizes, on='race_id')
    return pred_df




def zen_to_han(s):
    """å…¨è§’æ•°å­—ã‚’åŠè§’ã«å¤‰æ›"""
    if pd.isna(s):
        return np.nan
    s = str(s)
    zen = 'ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™'
    han = '0123456789'
    for z, h in zip(zen, han):
        s = s.replace(z, h)
    try:
        return int(s) if s.isdigit() else np.nan
    except:
        return np.nan


def load_historical_data_from_csv():
    """æ–°CSVã‹ã‚‰éå»ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆè„šè³ªãƒ»å‰èµ°æƒ…å ±ä»˜ãï¼‰"""
    print("ğŸ“š éå»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­ï¼ˆæ–°CSVï¼‰...")
    
    csv_path = CSV_DIR / 'results' / '20150105_20251130all.csv'
    
    if not csv_path.exists():
        print(f"âš ï¸  CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        return load_historical_data()  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    
    # å¿…è¦ãªã‚«ãƒ©ãƒ ã®ã¿èª­ã¿è¾¼ã¿
    use_cols = [
        'æ—¥ä»˜', 'å ´æ‰€', 'ï¼²', 'é¦¬ç•ª', 'é¦¬å', 'ç€é †', 'å˜å‹ã‚ªãƒƒã‚º', 'äººæ°—',
        'å¹´é½¢', 'æ€§åˆ¥', 'é¨æ‰‹', 'èª¿æ•™å¸«', 'é¦¬ä½“é‡', 'æ–¤é‡', 'æ ç•ª', 'ä¸Šã‚Š3F',
        'é ­æ•°', 'èŠãƒ»ãƒ€', 'è·é›¢', 'é¦¬å ´çŠ¶æ…‹', 'å¤©æ°—', 'ã‚¯ãƒ©ã‚¹å',
        'è„šè³ª', 'å‰èµ°ç€é †', 'å‰èµ°è„šè³ª', 'é–“éš”'
    ]
    
    df = pd.read_csv(csv_path, encoding='cp932', usecols=use_cols, low_memory=False)
    
    # ã‚«ãƒ©ãƒ åå¤‰æ›
    df = df.rename(columns={
        'æ—¥ä»˜': 'date_raw',
        'å ´æ‰€': 'place_name',
        'ï¼²': 'race_no',
        'é¦¬ç•ª': 'horse_no',
        'é¦¬å': 'horse_name',
        'ç€é †': 'finish_position_raw',
        'å˜å‹ã‚ªãƒƒã‚º': 'odds_win',
        'äººæ°—': 'popularity',
        'å¹´é½¢': 'horse_age',
        'æ€§åˆ¥': 'horse_sex',
        'é¨æ‰‹': 'jockey_name',
        'èª¿æ•™å¸«': 'trainer_name',
        'é¦¬ä½“é‡': 'horse_weight',
        'æ–¤é‡': 'load_weight',
        'æ ç•ª': 'gate_no',
        'ä¸Šã‚Š3F': 'last_3f_time',
        'é ­æ•°': 'field_size',
        'èŠãƒ»ãƒ€': 'track_type',
        'è·é›¢': 'distance',
        'é¦¬å ´çŠ¶æ…‹': 'track_condition',
        'å¤©æ°—': 'weather',
        'ã‚¯ãƒ©ã‚¹å': 'race_class',
        'è„šè³ª': 'running_style',
        'å‰èµ°ç€é †': 'prev_finish_raw',
        'å‰èµ°è„šè³ª': 'prev_running_style',
        'é–“éš”': 'rest_weeks'
    })
    
    # ãƒ‡ãƒ¼ã‚¿å¤‰æ›
    # æ—¥ä»˜å¤‰æ› (YYMMDD â†’ YYYY-MM-DD)
    df['date'] = df['date_raw'].apply(lambda x: f"20{str(x)[:2]}-{str(x)[2:4]}-{str(x)[4:6]}" if pd.notna(x) else None)
    
    # ç€é †å¤‰æ›ï¼ˆå…¨è§’â†’åŠè§’ï¼‰
    df['finish_position'] = df['finish_position_raw'].apply(zen_to_han)
    
    # å‰èµ°ç€é †å¤‰æ›ï¼ˆå…¨è§’â†’åŠè§’ï¼‰
    df['prev_finish'] = df['prev_finish_raw'].apply(zen_to_han)
    
    # å¤©æ°—ã®trim
    df['weather'] = df['weather'].str.strip() if df['weather'].dtype == 'object' else df['weather']
    
    # ãƒˆãƒ©ãƒƒã‚¯ã‚¿ã‚¤ãƒ—å¤‰æ›
    df['track_type'] = df['track_type'].replace({'ãƒ€': 'ãƒ€ãƒ¼ãƒˆ'})
    
    # å ´æ‰€ã‚³ãƒ¼ãƒ‰è¿½åŠ 
    place_to_code = {
        'æœ­å¹Œ': '01', 'å‡½é¤¨': '02', 'ç¦å³¶': '03', 'æ–°æ½Ÿ': '04',
        'æ±äº¬': '05', 'ä¸­å±±': '06', 'ä¸­äº¬': '07', 'äº¬éƒ½': '08',
        'é˜ªç¥': '09', 'å°å€‰': '10'
    }
    df['place_code'] = df['place_name'].map(place_to_code)
    
    # race_idç”Ÿæˆ
    df['race_id'] = df['date'] + '_' + df['place_code'] + '_' + df['race_no'].astype(str).str.zfill(2)
    
    # è„šè³ªã‚¹ã‚³ã‚¢ï¼ˆå‹ç‡ãƒ™ãƒ¼ã‚¹ï¼‰
    running_style_score = {
        'é€ƒã’': 19.5,
        'å…ˆè¡Œ': 13.9,
        'ä¸­å›£': 4.9,
        'å¾Œæ–¹': 1.4,
        'ï¾ï½¸ï¾˜': 16.3,
        'ä¸æ˜': 5.0
    }
    df['running_style_score'] = df['running_style'].map(running_style_score).fillna(5.0)
    
    # å‰èµ°ç€é †ã‚¹ã‚³ã‚¢
    prev_finish_score = {
        1: 11.2, 2: 20.2, 3: 14.1, 4: 10.4, 5: 7.8,
        6: 6.0, 7: 5.0, 8: 4.0, 9: 3.5, 10: 3.0
    }
    df['prev_finish_score'] = df['prev_finish'].map(prev_finish_score).fillna(5.0)
    
    # æ•°å€¤å‹å¤‰æ›
    numeric_cols = ['odds_win', 'popularity', 'horse_age', 'horse_weight', 
                    'load_weight', 'gate_no', 'last_3f_time', 'field_size', 'distance']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º
    df = df[
        (df['finish_position'].notna()) & 
        (df['finish_position'] > 0) &
        (df['odds_win'].notna()) & 
        (df['odds_win'] > 0)
    ]
    
    # ãƒ¬ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹åˆ¤å®š
    df['is_graded'] = df['race_class'].str.contains('ï¼§', na=False)
    df['is_maiden'] = df['race_class'].str.contains('æ–°é¦¬|æœªå‹åˆ©', na=False)
    
    print(f"  â†’ {len(df):,}ä»¶ï¼ˆè„šè³ªãƒ»å‰èµ°æƒ…å ±ä»˜ãï¼‰")
    
    return df

def load_historical_data():
    print("ğŸ“š éå»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    conn = sqlite3.connect(DB_PATH)

    query = """
        SELECT rr.race_id, rr.date, rr.place_code, rr.race_no,
            rr.horse_no, rr.horse_name, rr.horse_age, rr.horse_sex,
            rr.jockey_name, rr.trainer_name, rr.load_weight, rr.gate_no,
            rr.odds_win, rr.popularity, rr.finish_position,
            rr.field_size, rr.last_3f_time, rr.time,
            rd.distance, rd.track_type, rd.track_condition, rd.weather, rd.race_class
        FROM race_results rr
        LEFT JOIN race_details rd ON rr.race_id = rd.race_id
        WHERE rr.finish_position IS NOT NULL AND rr.finish_position > 0
          AND rr.odds_win IS NOT NULL AND rr.odds_win > 0
    """

    df = pd.read_sql_query(query, conn)
    conn.close()

    if 'race_class' not in df.columns or df['race_class'].isna().all():
        df['race_class'] = 'æ¡ä»¶'

    print(f"  â†’ {len(df):,}ä»¶")
    return df


def create_features(df, is_prediction=False):
    features = pd.DataFrame()

    features['odds_log'] = np.log1p(df['odds_win'].fillna(100))
    features['odds_place_log'] = np.log1p(df['odds_place_low'].fillna(50)) if 'odds_place_low' in df.columns else features['odds_log'] * 0.3
    features['load_weight'] = df['load_weight'].fillna(55)
    features['weight_ratio'] = df['load_weight'] / 55.0
    features['horse_age'] = df['horse_age'].fillna(3)

    sex_map = {'ç‰¡': 0, 'ç‰': 1, 'ã‚»': 2}
    features['horse_sex_num'] = df['horse_sex'].map(sex_map).fillna(0)

    track_map = {'èŠ': 0, 'ãƒ€ãƒ¼ãƒˆ': 1}
    features['track_type_num'] = df['track_type'].map(track_map).fillna(0)

    condition_map = {'è‰¯': 0, 'ç¨€é‡': 1, 'é‡': 2, 'ä¸è‰¯': 3}
    features['track_condition_num'] = df['track_condition'].map(condition_map).fillna(0)

    weather_map = {'æ™´': 0, 'æ›‡': 1, 'å°é›¨': 2, 'é›¨': 3, 'å°é›ª': 4, 'é›ª': 5}
    features['weather_num'] = df['weather'].map(weather_map).fillna(0)

    features['distance'] = df['distance'].fillna(1600)
    features['distance_cat'] = pd.cut(df['distance'], bins=[0, 1200, 1400, 1800, 2200, 9999], labels=[0, 1, 2, 3, 4]).astype(float).fillna(2)

    features['gate_no'] = df['gate_no'].fillna(4)
    features['horse_no'] = df['horse_no'].fillna(8)
    features['field_size'] = df['field_size'].fillna(16)
    features['horse_no_ratio'] = df['horse_no'] / df['field_size'].replace(0, 1)
    features['is_outside'] = (features['horse_no_ratio'] >= 0.8).astype(int)

    features['is_graded'] = df['is_graded'].astype(int) if 'is_graded' in df.columns else 0
    features['is_maiden'] = df['is_maiden'].astype(int) if 'is_maiden' in df.columns else 0


    # === æ–°ç‰¹å¾´é‡ï¼ˆè„šè³ªãƒ»å‰èµ°æƒ…å ±ï¼‰===
    if 'running_style_score' in df.columns:
        features['running_style_score'] = df['running_style_score'].fillna(5.0)
    else:
        features['running_style_score'] = 5.0

    if 'prev_finish_score' in df.columns:
        features['prev_finish_score'] = df['prev_finish_score'].fillna(5.0)
    else:
        features['prev_finish_score'] = 5.0

    if 'rest_weeks' in df.columns:
        features['rest_weeks'] = df['rest_weeks'].fillna(4).clip(0, 52)
        features['rest_weeks_optimal'] = ((df['rest_weeks'] >= 2) & (df['rest_weeks'] <= 4)).astype(int)
    else:
        features['rest_weeks'] = 4
        features['rest_weeks_optimal'] = 1

    return features


def train_model(hist_df):
    print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­...")

    hist_df['is_graded'] = hist_df['race_class'].apply(lambda x: is_graded_race(str(x)) if pd.notna(x) else False)
    hist_df['is_maiden'] = hist_df['race_class'].apply(lambda x: is_maiden_race(str(x)) if pd.notna(x) else False)

    X = create_features(hist_df)
    y = (hist_df['finish_position'] <= 3).astype(int)

    feature_cols = X.columns.tolist()

    model = lgb.LGBMClassifier(
        n_estimators=300, learning_rate=0.02, num_leaves=25, max_depth=6,
        min_child_samples=50, lambda_l1=0.1, lambda_l2=0.2,
        feature_fraction=0.8, bagging_fraction=0.8, bagging_freq=5,
        random_state=42, verbose=-1
    )
    model.fit(X, y)
    print(f"  â†’ ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
    return model, feature_cols


def predict_races(model, feature_cols, pred_df):
    print("ğŸ¯ äºˆæ¸¬å®Ÿè¡Œä¸­...")

    df = pred_df.copy()
    df['track_condition'] = 'è‰¯'
    df['weather'] = 'æ™´'

    X_pred = create_features(df, is_prediction=True)

    for col in feature_cols:
        if col not in X_pred.columns:
            X_pred[col] = 0

    X_pred = X_pred[feature_cols]
    probs = model.predict_proba(X_pred)[:, 1]
    df['pred_prob'] = probs
    df['score'] = df['pred_prob'] * 100

    # AIã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹ãƒ©ãƒ³ã‚¯
    df['pred_rank'] = df.groupby('race_id')['pred_prob'].rank(ascending=False, method='first').astype(int)

    # äººæ°—é †ï¼ˆã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ï¼‰
    if df['odds_win'].notna().any():
        df['popularity'] = df.groupby('race_id')['odds_win'].rank(method='first').astype(int)
    else:
        df['popularity'] = df['pred_rank']  # ã‚ªãƒƒã‚ºãŒãªã„å ´åˆã¯AIãƒ©ãƒ³ã‚¯ã§ä»£ç”¨

    # ã‚®ãƒ£ãƒƒãƒ—æŒ‡æ¨™ = äººæ°—é † - AIãƒ©ãƒ³ã‚¯ï¼ˆãƒ—ãƒ©ã‚¹ = éå°è©•ä¾¡ = ç‹™ã„ç›®ï¼‰
    df['gap'] = df['popularity'] - df['pred_rank']

    return df


def select_recommended_races(result_df):
    """3ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®æ¨å¥¨ãƒ¬ãƒ¼ã‚¹ã‚’é¸å®šï¼ˆã‚ªãƒƒã‚ºåŸºæº–ãƒ»ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ v2.5ï¼‰"""

    # æ–°é¦¬ãƒ»æœªå‹åˆ©ã¯é™¤å¤–
    target_df = result_df[result_df['is_maiden'] == False].copy()

    # ã‚ªãƒƒã‚ºãŒãªã„é¦¬ã‚’é™¤å¤–
    target_df = target_df[target_df['odds_win'].notna()]

    recommended = {}
    used_race_ids = set()

    # ============================================================
    # ğŸ”µ é‰„æ¿: AIãƒ©ãƒ³ã‚¯1ä½ Ã— ã‚ªãƒƒã‚º1.0ã€œ5.0å€ Ã— 1ã€œ3ç•ªäººæ°—
    # ç›®çš„: å …å®Ÿã«çš„ä¸­ã€é¦¬é€£ã€œ2,000å††
    # ============================================================
    teppan_candidates = target_df[
        (target_df['pred_rank'] == 1) &
        (target_df['popularity'] >= 1) &
        (target_df['popularity'] <= 3) &
        (target_df['odds_win'] >= 1.0) &
        (target_df['odds_win'] <= 5.0) &
        (target_df['score'] >= 50.0)
    ].copy()

    if len(teppan_candidates) == 0:
        # æ¡ä»¶ç·©å’Œ: ã‚ªãƒƒã‚º7.0å€ã¾ã§ã€ã‚¹ã‚³ã‚¢45ä»¥ä¸Š
        teppan_candidates = target_df[
            (target_df['pred_rank'] == 1) &
            (target_df['popularity'] >= 1) &
            (target_df['popularity'] <= 4) &
            (target_df['odds_win'] >= 1.0) &
            (target_df['odds_win'] <= 7.0) &
            (target_df['score'] >= 45.0)
        ].copy()

    if len(teppan_candidates) > 0:
        # ã‚¹ã‚³ã‚¢æœ€é«˜ã®ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠ
        best = teppan_candidates.loc[teppan_candidates['score'].idxmax()]
        race_id = best['race_id']
        race_df = result_df[result_df['race_id'] == race_id].copy()
        recommended['TEPPAN'] = create_recommendation(best, race_df, 'TEPPAN')
        used_race_ids.add(race_id)

    # ============================================================
    # ğŸŸ¡ ä¸­ç©´: AIãƒ©ãƒ³ã‚¯1ã€œ3ä½ Ã— ã‚ªãƒƒã‚º7.0å€ä»¥ä¸Š
    # ç›®çš„: é¦¬é€£2,000ã€œ10,000å††
    # äººæ°—æ¡ä»¶æ’¤å»ƒ â†’ ã‚ªãƒƒã‚ºã®ã¿ã§åˆ¤å®š
    # ============================================================
    chuuana_candidates = target_df[
        (~target_df['race_id'].isin(used_race_ids)) &
        (target_df['pred_rank'] <= 3) &
        (target_df['odds_win'] >= 7.0) &
        (target_df['score'] >= 20.0)
    ].copy()

    if len(chuuana_candidates) == 0:
        # æ¡ä»¶ç·©å’Œ: ã‚ªãƒƒã‚º5.0å€ä»¥ä¸Šã€ã‚¹ã‚³ã‚¢15ä»¥ä¸Š
        chuuana_candidates = target_df[
            (~target_df['race_id'].isin(used_race_ids)) &
            (target_df['pred_rank'] <= 3) &
            (target_df['odds_win'] >= 5.0) &
            (target_df['score'] >= 15.0)
        ].copy()

    if len(chuuana_candidates) > 0:
        # ã‚¹ã‚³ã‚¢Ã—ã‚ªãƒƒã‚ºã§ä¾¡å€¤ãŒé«˜ã„ã‚‚ã®ã‚’é¸æŠ
        chuuana_candidates['value'] = chuuana_candidates['score'] * np.log1p(chuuana_candidates['odds_win'])
        best = chuuana_candidates.loc[chuuana_candidates['value'].idxmax()]
        race_id = best['race_id']
        race_df = result_df[result_df['race_id'] == race_id].copy()
        recommended['CHUUANA'] = create_recommendation(best, race_df, 'CHUUANA')
        used_race_ids.add(race_id)

    # ============================================================
    # ğŸ”´ å¤§ç©´: ã‚ªãƒƒã‚º20å€ä»¥ä¸Šã®ä¸­ã§ã‚¹ã‚³ã‚¢æœ€é«˜ã®é¦¬
    # ç›®çš„: é¦¬é€£10,000å††ä»¥ä¸Šï¼ˆä¸‡é¦¬åˆ¸ï¼‰
    # ã‚·ãƒ³ãƒ—ãƒ«: ã‚ªãƒƒã‚º20å€ä»¥ä¸Š â†’ ã‚¹ã‚³ã‚¢æœ€é«˜ã‚’é¸å®š
    # ============================================================
    ooana_candidates = target_df[
        (~target_df['race_id'].isin(used_race_ids)) &
        (target_df['odds_win'] >= 20.0)
    ].copy()

    if len(ooana_candidates) == 0:
        # æ¡ä»¶ç·©å’Œ: ã‚ªãƒƒã‚º15å€ä»¥ä¸Š
        ooana_candidates = target_df[
            (~target_df['race_id'].isin(used_race_ids)) &
            (target_df['odds_win'] >= 15.0)
        ].copy()

    if len(ooana_candidates) > 0:
        # ã‚¹ã‚³ã‚¢æœ€é«˜ã®é¦¬ã‚’é¸æŠ
        best = ooana_candidates.loc[ooana_candidates['score'].idxmax()]
        race_id = best['race_id']
        race_df = result_df[result_df['race_id'] == race_id].copy()
        recommended['OOANA'] = create_recommendation(best, race_df, 'OOANA')

    return recommended


def create_recommendation(honmei_row, race_df, cat_key):
    """æ¨å¥¨ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’ä½œæˆï¼ˆè²·ã„ç›®ä»˜ãï¼‰"""
    config = CATEGORY_CONFIG[cat_key]
    
    # ãƒ¬ãƒ¼ã‚¹å†…ã®é¦¬ã‚’AIã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
    race_df = race_df.sort_values('pred_rank')
    
    # å°ã‚’ã¤ã‘ã‚‹é¦¬ã‚’å–å¾—ï¼ˆâ—â—‹â–²â–³â˜†ï¼‰
    top_horses = race_df.head(7).to_dict('records')
    
    # å°ã®å‰²ã‚Šå½“ã¦
    marks = ['â—', 'â—‹', 'â–²', 'â–³', 'â–³', 'â˜†', 'â˜†']
    marked_horses = []
    for i, horse in enumerate(top_horses):
        marked_horses.append({
            'mark': marks[i] if i < len(marks) else 'Ã—',
            'horse_no': int(horse['horse_no']),
            'horse_name': horse['horse_name'],
            'jockey_name': horse['jockey_name'],
            'odds_win': float(horse['odds_win']) if pd.notna(horse['odds_win']) else None,
            'popularity': int(horse['popularity']) if pd.notna(horse['popularity']) else None,
            'score': round(horse['score'], 1),
            'rank': int(horse['pred_rank']),
            'gap': int(horse['gap']) if pd.notna(horse.get('gap')) else 0
        })
    
    # è²·ã„ç›®ç”Ÿæˆ
    bets = generate_bets(marked_horses, cat_key)
    
    return {
        'race_id': honmei_row['race_id'],
        'place_name': honmei_row['place_name'],
        'race_no': int(honmei_row['race_no']),
        'race_name': honmei_row['race_name'],
        'track_type': honmei_row['track_type'],
        'distance': int(honmei_row['distance']),
        'field_size': int(honmei_row['field_size']),
        'category': cat_key,
        'category_name': config['name'],
        'category_emoji': config['emoji'],
        'description': config['description'],
        'bet_style': config['bet_style'],
        # æœ¬å‘½é¦¬æƒ…å ±
        'honmei': {
            'horse_no': int(honmei_row['horse_no']),
            'horse_name': honmei_row['horse_name'],
            'jockey_name': honmei_row['jockey_name'],
            'score': round(honmei_row['score'], 1),
            'odds_win': float(honmei_row['odds_win']) if pd.notna(honmei_row['odds_win']) else None,
            'popularity': int(honmei_row['popularity']) if pd.notna(honmei_row['popularity']) else None,
            'gap': int(honmei_row['gap']) if pd.notna(honmei_row.get('gap')) else 0
        },
        # å°ä»˜ãé¦¬ãƒªã‚¹ãƒˆ
        'marked_horses': marked_horses,
        # è²·ã„ç›®
        'bets': bets
    }


def generate_bets(marked_horses, cat_key):
    """ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã®è²·ã„ç›®ã‚’ç”Ÿæˆ"""
    
    if len(marked_horses) < 3:
        return {'error': 'é¦¬ãŒä¸è¶³ã—ã¦ã„ã¾ã™'}
    
    # é¦¬ç•ªã‚’å–å¾—
    h1 = marked_horses[0]['horse_no']  # â—
    h2 = marked_horses[1]['horse_no']  # â—‹
    h3 = marked_horses[2]['horse_no']  # â–²
    h4 = marked_horses[3]['horse_no'] if len(marked_horses) > 3 else None  # â–³
    h5 = marked_horses[4]['horse_no'] if len(marked_horses) > 4 else None  # â–³
    h6 = marked_horses[5]['horse_no'] if len(marked_horses) > 5 else None  # â˜†
    h7 = marked_horses[6]['horse_no'] if len(marked_horses) > 6 else None  # â˜†
    
    bets = {}
    
    # ============================================================
    # å˜å‹ï¼ˆå…¨ã‚«ãƒ†ã‚´ãƒªãƒ¼å…±é€š: â—1ç‚¹ï¼‰
    # ============================================================
    bets['tansho'] = {
        'type': 'å˜å‹',
        'points': 1,
        'bets': [f"{h1}"]
    }
    
    # ============================================================
    # é¦¬é€£
    # ============================================================
    if cat_key == 'TEPPAN':
        # é‰„æ¿: â—-â—‹ 1ç‚¹
        bets['umaren'] = {
            'type': 'é¦¬é€£',
            'points': 1,
            'bets': [f"{h1}-{h2}"]
        }
    elif cat_key == 'CHUUANA':
        # ä¸­ç©´: â—-â—‹â–² 2ç‚¹
        bets['umaren'] = {
            'type': 'é¦¬é€£',
            'points': 2,
            'bets': [f"{h1}-{h2}", f"{h1}-{h3}"]
        }
    else:  # OOANA
        # å¤§ç©´: â—-â—‹â–²â–³ 3ç‚¹
        umaren_bets = [f"{h1}-{h2}", f"{h1}-{h3}"]
        if h4:
            umaren_bets.append(f"{h1}-{h4}")
        bets['umaren'] = {
            'type': 'é¦¬é€£',
            'points': len(umaren_bets),
            'bets': umaren_bets
        }
    
    # ============================================================
    # 3é€£è¤‡
    # ============================================================
    if cat_key == 'TEPPAN':
        # é‰„æ¿: â—-â—‹â–²-â—‹â–²â–³ (6ç‚¹)
        # ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³: 1ç€â—ã€2ç€â—‹â–²ã€3ç€â—‹â–²â–³
        sanrenpuku_bets = []
        aite_2 = [h2, h3]
        aite_3 = [h2, h3]
        if h4:
            aite_3.append(h4)
        
        for a2 in aite_2:
            for a3 in aite_3:
                if a2 != a3:
                    combo = tuple(sorted([h1, a2, a3]))
                    bet_str = f"{combo[0]}-{combo[1]}-{combo[2]}"
                    if bet_str not in sanrenpuku_bets:
                        sanrenpuku_bets.append(bet_str)
        
        bets['sanrenpuku'] = {
            'type': '3é€£è¤‡',
            'points': len(sanrenpuku_bets),
            'formation': f"â—{h1} - â—‹â–² - â—‹â–²â–³",
            'bets': sanrenpuku_bets
        }
        
    elif cat_key == 'CHUUANA':
        # ä¸­ç©´: â—-â—‹â–²â–³-â—‹â–²â–³â˜† (12ç‚¹ç¨‹åº¦)
        sanrenpuku_bets = []
        aite_2 = [h2, h3]
        if h4:
            aite_2.append(h4)
        aite_3 = [h2, h3]
        if h4:
            aite_3.append(h4)
        if h6:
            aite_3.append(h6)
        
        for a2 in aite_2:
            for a3 in aite_3:
                if a2 != a3:
                    combo = tuple(sorted([h1, a2, a3]))
                    bet_str = f"{combo[0]}-{combo[1]}-{combo[2]}"
                    if bet_str not in sanrenpuku_bets:
                        sanrenpuku_bets.append(bet_str)
        
        bets['sanrenpuku'] = {
            'type': '3é€£è¤‡',
            'points': len(sanrenpuku_bets),
            'formation': f"â—{h1} - â—‹â–²â–³ - â—‹â–²â–³â˜†",
            'bets': sanrenpuku_bets
        }
        
    else:  # OOANA
        # å¤§ç©´: 2-4-7å½¢å¼ (19ç‚¹)
        # 1åˆ—ç›®: â—â—‹ã€2åˆ—ç›®: â—â—‹â–²â–³ã€3åˆ—ç›®: â—‹â–²â–³â–³â˜†â˜†â˜…
        sanrenpuku_bets = []
        col1 = [h1, h2]
        col2 = [h1, h2, h3]
        if h4:
            col2.append(h4)
        col3 = [h2, h3]
        if h4:
            col3.append(h4)
        if h5:
            col3.append(h5)
        if h6:
            col3.append(h6)
        if h7:
            col3.append(h7)
        
        for c1 in col1:
            for c2 in col2:
                for c3 in col3:
                    if len(set([c1, c2, c3])) == 3:  # é‡è¤‡ãªã—
                        combo = tuple(sorted([c1, c2, c3]))
                        bet_str = f"{combo[0]}-{combo[1]}-{combo[2]}"
                        if bet_str not in sanrenpuku_bets:
                            sanrenpuku_bets.append(bet_str)
        
        bets['sanrenpuku'] = {
            'type': '3é€£è¤‡',
            'points': len(sanrenpuku_bets),
            'formation': f"â—â—‹ - â—â—‹â–²â–³ - â—‹â–²â–³â–³â˜†â˜†",
            'bets': sanrenpuku_bets
        }
    
    # ============================================================
    # 3é€£å˜
    # ============================================================
    if cat_key == 'TEPPAN':
        # é‰„æ¿: â—â†’â—‹â–²â†’â—‹â–²â–³ (6ç‚¹)
        sanrentan_bets = []
        for second in [h2, h3]:
            for third in [h2, h3]:
                if h4:
                    for t in [h2, h3, h4]:
                        if second != t and h1 != t:
                            bet_str = f"{h1}â†’{second}â†’{t}"
                            if bet_str not in sanrentan_bets:
                                sanrentan_bets.append(bet_str)
                else:
                    if second != third:
                        bet_str = f"{h1}â†’{second}â†’{third}"
                        if bet_str not in sanrentan_bets:
                            sanrentan_bets.append(bet_str)
        
        bets['sanrentan'] = {
            'type': '3é€£å˜',
            'points': len(sanrentan_bets),
            'formation': f"â—{h1} â†’ â—‹â–² â†’ â—‹â–²â–³",
            'bets': sanrentan_bets
        }
        
    elif cat_key == 'CHUUANA':
        # ä¸­ç©´: â—â†’â—‹â–²â†’â—‹â–²â–³â–³ (12ç‚¹ç¨‹åº¦)
        sanrentan_bets = []
        seconds = [h2, h3]
        thirds = [h2, h3]
        if h4:
            thirds.append(h4)
        if h5:
            thirds.append(h5)
        
        for second in seconds:
            for third in thirds:
                if second != third:
                    bet_str = f"{h1}â†’{second}â†’{third}"
                    if bet_str not in sanrentan_bets:
                        sanrentan_bets.append(bet_str)
        
        bets['sanrentan'] = {
            'type': '3é€£å˜',
            'points': len(sanrentan_bets),
            'formation': f"â—{h1} â†’ â—‹â–² â†’ â—‹â–²â–³â–³",
            'bets': sanrentan_bets
        }
        
    else:  # OOANA
        # å¤§ç©´: â—â—‹â†’â—â—‹â–²â†’â—‹â–²â–³â–³â–³ (24ç‚¹ç¨‹åº¦)
        sanrentan_bets = []
        firsts = [h1, h2]
        seconds = [h1, h2, h3]
        thirds = [h2, h3]
        if h4:
            thirds.append(h4)
        if h5:
            thirds.append(h5)
        if h6:
            thirds.append(h6)
        
        for first in firsts:
            for second in seconds:
                for third in thirds:
                    if len(set([first, second, third])) == 3:
                        bet_str = f"{first}â†’{second}â†’{third}"
                        if bet_str not in sanrentan_bets:
                            sanrentan_bets.append(bet_str)
        
        bets['sanrentan'] = {
            'type': '3é€£å˜',
            'points': len(sanrentan_bets),
            'formation': f"â—â—‹ â†’ â—â—‹â–² â†’ â—‹â–²â–³â–³â–³",
            'bets': sanrentan_bets
        }
    
    # åˆè¨ˆç‚¹æ•°
    total_points = sum(b['points'] for b in bets.values() if isinstance(b, dict) and 'points' in b)
    bets['total_points'] = total_points
    
    return bets


def print_predictions(pred_df, recommended):
    """äºˆæ¸¬çµæœã‚’è¡¨ç¤º"""

    # ã¾ãšæ¨å¥¨ãƒ¬ãƒ¼ã‚¹3é¸ã‚’è¡¨ç¤º
    print()
    print("=" * 70)
    print("ğŸ† æœ¬æ—¥ã®æ¨å¥¨ãƒ¬ãƒ¼ã‚¹3é¸ã€äººæ°—ã®ç›²ç‚¹ã§é¸å®šã€‘")
    print("=" * 70)

    for cat_key in ['TEPPAN', 'CHUUANA', 'OOANA']:
        if cat_key in recommended:
            r = recommended[cat_key]
            config = CATEGORY_CONFIG[cat_key]
            honmei = r['honmei']
            bets = r['bets']
            
            print()
            print(f"{config['emoji']} ã€{config['name']}ã€‘{config['description']}")
            print("-" * 60)
            print(f"ğŸ“ {r['place_name']}{r['race_no']}R {r['race_name']}")
            print(f"   {r['track_type']}{r['distance']}m ï½œ {r['field_size']}é ­ç«‹")
            print()
            
            # æœ¬å‘½é¦¬æƒ…å ±
            gap_str = f"+{honmei['gap']}" if honmei['gap'] > 0 else str(honmei['gap'])
            print(f"   â—æœ¬å‘½: {honmei['horse_no']}ç•ª {honmei['horse_name']} ({honmei['jockey_name']})")
            print(f"   ã€€ã€€ã€€ ã‚¹ã‚³ã‚¢: {honmei['score']}% | ã‚ªãƒƒã‚º: {honmei['odds_win']:.1f}å€ | {honmei['popularity']}ç•ªäººæ°—")
            print(f"   ã€€ã€€ã€€ ã‚®ãƒ£ãƒƒãƒ—: {gap_str} {'ğŸ‘€äººæ°—ã®ç›²ç‚¹!' if honmei['gap'] >= 2 else ''}")
            print()
            
            # å°ä»˜ãé¦¬ä¸€è¦§
            print("   ã€äºˆæƒ³å°ã€‘")
            for h in r['marked_horses'][:5]:
                gap_mark = f"(+{h['gap']})" if h['gap'] > 0 else f"({h['gap']})" if h['gap'] < 0 else ""
                pop_str = f"{h['popularity']}äººæ°—" if h['popularity'] else "-"
                print(f"   {h['mark']} {h['horse_no']:2d} {h['horse_name'][:8]:<10} [{h['score']:>5.1f}%] {h['odds_win']:>5.1f}å€ {pop_str} {gap_mark}")
            print()
            
            # è²·ã„ç›®ã‚µãƒãƒªãƒ¼
            print(f"   ã€è²·ã„ç›®ã€‘åˆè¨ˆ {bets['total_points']}ç‚¹")
            print(f"   ã€€å˜å‹: {', '.join(bets['tansho']['bets'])} ({bets['tansho']['points']}ç‚¹)")
            print(f"   ã€€é¦¬é€£: {', '.join(bets['umaren']['bets'])} ({bets['umaren']['points']}ç‚¹)")
            print(f"   ã€€3é€£è¤‡: {bets['sanrenpuku']['formation']} ({bets['sanrenpuku']['points']}ç‚¹)")
            print(f"   ã€€3é€£å˜: {bets['sanrentan']['formation']} ({bets['sanrentan']['points']}ç‚¹)")
            
        else:
            config = CATEGORY_CONFIG[cat_key]
            print()
            print(f"{config['emoji']} ã€{config['name']}ã€‘è©²å½“ãƒ¬ãƒ¼ã‚¹ãªã—")

    print()
    print("=" * 70)
    print("ğŸ“‹ å…¨ãƒ¬ãƒ¼ã‚¹äºˆæƒ³ä¸€è¦§")
    print("=" * 70)

    for place_code in sorted(pred_df['place_code'].unique()):
        place_df = pred_df[pred_df['place_code'] == place_code]
        place_name = place_df['place_name'].iloc[0]

        for race_id in sorted(place_df['race_id'].unique()):
            race_df = place_df[place_df['race_id'] == race_id].copy()
            race_df = race_df.sort_values('pred_rank')
            first = race_df.iloc[0]

            # æ¨å¥¨ãƒ¬ãƒ¼ã‚¹ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯
            rec_mark = ""
            for cat_key, r in recommended.items():
                if r['race_id'] == race_id:
                    rec_mark = f" {CATEGORY_CONFIG[cat_key]['emoji']}æ¨å¥¨"
                    break

            race_type_str = ""
            if first['is_maiden']:
                race_type_str = " âš ï¸æ–°é¦¬/æœªå‹åˆ©"
            elif first['is_graded']:
                race_type_str = " â˜…é‡è³"

            print()
            print(f"ğŸ“ {place_name}{first['race_no']}R {first['race_name']}{race_type_str}{rec_mark}")
            print(f"   {first['track_type']}{first['distance']}m {first['field_size']}é ­ç«‹")

            marks = ['â—', 'â—‹', 'â–²', 'â–³', 'â˜†']
            for i, (_, row) in enumerate(race_df.head(5).iterrows()):
                mark = marks[i] if i < len(marks) else '  '
                odds_str = f"[{row['odds_win']:.1f}å€]" if pd.notna(row['odds_win']) else ""
                pop_str = f"{int(row['popularity'])}äººæ°—" if pd.notna(row['popularity']) else ""
                gap_str = f"(+{int(row['gap'])})" if pd.notna(row.get('gap')) and row['gap'] > 0 else ""
                print(f"   {mark} {row['horse_no']:2d} {row['horse_name'][:10]:<12} [{row['score']:.1f}%] {odds_str} {pop_str} {gap_str}")


def generate_output(pred_df, recommended, has_odds):
    """äºˆæ¸¬çµæœã‚’JSONå‡ºåŠ›"""
    date_str = pred_df['date'].iloc[0]
    places_data = []

    for place_code in sorted(pred_df['place_code'].unique()):
        place_df = pred_df[pred_df['place_code'] == place_code]
        place_name = place_df['place_name'].iloc[0]
        races_data = []

        for race_id in sorted(place_df['race_id'].unique()):
            race_df = place_df[place_df['race_id'] == race_id].copy()
            race_df = race_df.sort_values('pred_rank')
            first = race_df.iloc[0]

            horses_data = []
            for _, row in race_df.iterrows():
                horse = {
                    'horse_no': int(row['horse_no']),
                    'horse_name': row['horse_name'],
                    'jockey_name': row['jockey_name'],
                    'load_weight': float(row['load_weight']) if pd.notna(row['load_weight']) else 0,
                    'sex_age': f"{row['horse_sex']}{row['horse_age']}",
                    'odds_win': float(row['odds_win']) if pd.notna(row['odds_win']) else None,
                    'popularity': int(row['popularity']) if pd.notna(row['popularity']) else None,
                    'score': round(row['score'], 1),
                    'rank': int(row['pred_rank']),
                    'gap': int(row['gap']) if pd.notna(row.get('gap')) else 0
                }
                horses_data.append(horse)

            # å°ã®å‰²ã‚Šå½“ã¦
            marks = ['â—', 'â—‹', 'â–²', 'â–³', 'â–³', 'â˜†', 'â˜†']
            for i, horse in enumerate(horses_data[:7]):
                horse['mark'] = marks[i] if i < len(marks) else 'Ã—'

            top3 = race_df.head(3)['horse_no'].astype(int).tolist()
            top5 = race_df.head(5)['horse_no'].astype(int).tolist()

            race_data = {
                'race_id': race_id,
                'race_no': int(first['race_no']),
                'race_name': first['race_name'],
                'race_class': first['race_class'],
                'is_graded': bool(first['is_graded']),
                'is_maiden': bool(first['is_maiden']),
                'distance': int(first['distance']),
                'track_type': first['track_type'],
                'field_size': int(first['field_size']),
                'top_score': round(first['score'], 1),
                'horses': horses_data,
                'recommended_bets': {
                    'tansho': f"{top3[0]}",
                    'umaren': f"{top3[0]}-{top3[1]}",
                    'umatan': f"{top3[0]}â†’{top3[1]}",
                    'wide': [f"{top3[0]}-{top3[1]}", f"{top3[0]}-{top3[2]}"],
                    'sanrenpuku': f"{top3[0]}-{top3[1]}-{top3[2]}",
                    'sanrentan': f"{top3[0]}â†’{top3[1]}â†’{top3[2]}"
                }
            }
            races_data.append(race_data)

        place_data = {
            'place_code': place_code,
            'place_name': place_name,
            'races': races_data
        }
        places_data.append(place_data)

    output = {
        'date': date_str,
        'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'has_odds': has_odds,
        'model_version': '2.4',
        'selection_method': 'äººæ°—ã®ç›²ç‚¹ï¼ˆã‚®ãƒ£ãƒƒãƒ—æŒ‡æ¨™ï¼‰',
        'bet_types': ['å˜å‹', 'é¦¬é€£', '3é€£è¤‡', '3é€£å˜'],
        'recommended_races': recommended,
        'places': places_data
    }

    return output


def main():
    parser = argparse.ArgumentParser(description='æ”¹å–„ç‰ˆäºˆæ¸¬ v2.4 - äººæ°—ã®ç›²ç‚¹ãƒ™ãƒ¼ã‚¹')
    parser.add_argument('date', nargs='?', default=None, help='æ—¥ä»˜ (YYYYMMDD)')
    args = parser.parse_args()

    print("=" * 70)
    print("ğŸ‡ Keiba Intelligence v2.4 - äººæ°—ã®ç›²ç‚¹ã§é¸ã¶3ã‚«ãƒ†ã‚´ãƒªãƒ¼æ¨å¥¨")
    print("=" * 70)
    print("ğŸ“Œ é¸å®šãƒ­ã‚¸ãƒƒã‚¯: ã‚®ãƒ£ãƒƒãƒ— = äººæ°—é † - AIãƒ©ãƒ³ã‚¯")
    print("   ãƒ—ãƒ©ã‚¹ãŒå¤§ãã„ã»ã©ã€Œéå°è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹é¦¬ã€= ç‹™ã„ç›®")
    print()
    print("ğŸ“Œ ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥æˆ¦ç•¥:")
    print("   ğŸ”µ é‰„æ¿: AIãƒ©ãƒ³ã‚¯1ä½ Ã— 1ã€œ2ç•ªäººæ°— â†’ é †å½“ãªæœ¬å‘½")
    print("   ğŸŸ¡ ä¸­ç©´: AIãƒ©ãƒ³ã‚¯ä¸Šä½ Ã— ä¸­ä½äººæ°— Ã— ã‚®ãƒ£ãƒƒãƒ—+2ä»¥ä¸Š â†’ å®ŸåŠ›é¦¬ã®éå°è©•ä¾¡")
    print("   ğŸ”´ å¤§ç©´: AIãƒ©ãƒ³ã‚¯ä¸Šä½ Ã— ä¸‹ä½äººæ°— Ã— ã‚®ãƒ£ãƒƒãƒ—+3ä»¥ä¸Š â†’ äººæ°—ã®ç›²ç‚¹")
    print()
    print("ğŸ“Œ è²·ã„ç›®: å˜å‹ãƒ»é¦¬é€£ãƒ»3é€£è¤‡ãƒ»3é€£å˜ï¼ˆTOP4é¦¬åˆ¸ç¨®ï¼‰")
    print()

    if args.date:
        date_str = args.date.replace('-', '').replace('/', '')
    else:
        csv_files = list(ENTRY_DIR.glob("DE*.CSV"))
        if not csv_files:
            print("âŒ å‡ºé¦¬è¡¨CSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        latest = sorted(csv_files)[-1]
        date_str = '20' + latest.stem[2:]

    print(f"ğŸ“… å¯¾è±¡æ—¥: {date_str[:4]}/{date_str[4:6]}/{date_str[6:8]}")
    print()

    entry_df = load_entry_csv(date_str)
    if entry_df is None:
        return

    odds_df = load_odds_csv(date_str)
    has_odds = odds_df is not None and len(odds_df) > 0

    if has_odds:
        merged_df = merge_entry_and_odds(entry_df, odds_df)
    else:
        merged_df = entry_df.copy()
        merged_df['place_code'] = merged_df['å ´æ‰€'].map(PLACE_CSV_TO_CODE)
        merged_df['odds_win'] = None

    pred_df = convert_to_predict_format(merged_df, date_str[2:])
    hist_df = load_historical_data_from_csv()
    model, feature_cols = train_model(hist_df)
    result_df = predict_races(model, feature_cols, pred_df)

    # æ¨å¥¨ãƒ¬ãƒ¼ã‚¹é¸å®šï¼ˆäººæ°—ã®ç›²ç‚¹ãƒ™ãƒ¼ã‚¹ï¼‰
    recommended = select_recommended_races(result_df)

    # çµæœè¡¨ç¤º
    print_predictions(result_df, recommended)


    # äºˆæ¸¬ãƒ­ã‚°è¨˜éŒ²
    try:
        logger = PredictionLogger(model_version='3.0')
        features_df = create_features(result_df, is_prediction=True)
        track_condition = result_df['track_condition'].iloc[0] if 'track_condition' in result_df.columns else 'è‰¯'
        weather = result_df['weather'].iloc[0] if 'weather' in result_df.columns else 'æ™´'
        log_result = logger.log_predictions(result_df, features_df, [], track_condition, weather)
        print(f"ğŸ“ äºˆæ¸¬ãƒ­ã‚°è¨˜éŒ²: {log_result.get('logged', 0)}ä»¶")
    except Exception as e:
        print(f"âš ï¸  äºˆæ¸¬ãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

    # JSONä¿å­˜
    output = generate_output(result_df, recommended, has_odds)

    PREDICTION_DIR.mkdir(parents=True, exist_ok=True)
    json_path = PREDICTION_DIR / f"predictions_{date_str}.json"

    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print()
    print("=" * 70)
    print("ğŸ“Š äºˆæ¸¬ã‚µãƒãƒªãƒ¼")
    print("=" * 70)
    print(f"  ç·ãƒ¬ãƒ¼ã‚¹æ•°: {result_df['race_id'].nunique()}")
    print(f"  å‡ºèµ°é ­æ•°: {len(result_df)}")
    print(f"  ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿: {'ã‚ã‚Š âœ…' if has_odds else 'ãªã— âš ï¸'}")
    print()
    
    # æ¨å¥¨ãƒ¬ãƒ¼ã‚¹ã®è²·ã„ç›®ç‚¹æ•°ã‚µãƒãƒªãƒ¼
    total_bets = 0
    for cat_key in ['TEPPAN', 'CHUUANA', 'OOANA']:
        if cat_key in recommended:
            points = recommended[cat_key]['bets']['total_points']
            total_bets += points
            print(f"  {CATEGORY_CONFIG[cat_key]['emoji']} {CATEGORY_CONFIG[cat_key]['name']}: {points}ç‚¹")
    print(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"  ğŸ“ æ¨å¥¨è²·ã„ç›®åˆè¨ˆ: {total_bets}ç‚¹")
    print()
    print(f"ğŸ’¾ JSONä¿å­˜: {json_path}")


if __name__ == '__main__':
    main()
















